ğŸ“ Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°:

 - bot.py
 - config.py
 - keyboards.py
 - test.py
 - tree.py
 - handlers\generation.py
 - handlers\info.py
 - handlers\prompt.py
 - handlers\start.py
 - handlers\vectorize.py
 - handlers\__init__.py
 - services\logo_generator.py
 - services\__init__.py
 - utils\states.py
 - utils\user_state.py
 - utils\__init__.py

ğŸ“„ Ğ¡Ğ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ğ¼Ğ¾Ğµ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²:


ğŸ”¹ bot.py:
------------------------------------------------------------
import logging
import asyncio
from aiogram import Bot, Dispatcher
from aiogram.enums import ParseMode
from aiogram.client.default import DefaultBotProperties
from aiogram.filters import CommandStart
from aiogram.fsm.storage.memory import MemoryStorage  # <- Ğ’ĞĞ–ĞĞ: Ğ´Ğ¾Ğ±Ğ°Ğ²ÑŒÑ‚Ğµ ÑÑ‚Ğ¾
from config import TELEGRAM_BOT_TOKEN
from handlers import start, info, prompt, generation, vectorize
from utils.user_state import get_user_state, STATE_GENERATE, STATE_VECTORIZE, STATE_MENU

logging.basicConfig(level=logging.INFO)
logging.getLogger("aiogram.event").setLevel(logging.DEBUG)

defaults = DefaultBotProperties(parse_mode=ParseMode.HTML)
bot = Bot(token=TELEGRAM_BOT_TOKEN, default=defaults)
dp = Dispatcher(storage=MemoryStorage())

def is_generate_text(message):
    return (
        message.text and not message.text.startswith("/")
        and get_user_state(message.from_user.id) == STATE_GENERATE
    )

def is_vectorization_photo(message):
    return (
        message.photo
        and get_user_state(message.from_user.id) == STATE_VECTORIZE
    )

dp.message.register(start.start, CommandStart())
dp.message.register(start.start, lambda m: m.text == "â¬…ï¸ Ğ’ Ğ¼ĞµĞ½Ñ")
dp.message.register(info.info, lambda m: m.text == "â„¹ï¸ Ğ˜Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ")
dp.message.register(prompt.prompt_for_idea, lambda m: m.text == "ğŸ¨ Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ»Ğ¾Ğ³Ğ¾Ñ‚Ğ¸Ğ¿Ğ°")
dp.message.register(vectorize.ask_for_image, lambda m: m.text == "ğŸ–¼ Ğ’ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ")
dp.message.register(vectorize.handle_vectorization_image, is_vectorization_photo)
dp.message.register(generation.handle_idea, is_generate_text)

@dp.message()
async def fallback_handler(message):
    state = get_user_state(message.from_user.id)
    if state == STATE_MENU:
        await message.answer("â—ï¸Ğ’Ñ‹ ÑĞµĞ¹Ñ‡Ğ°Ñ Ğ² Ğ³Ğ»Ğ°Ğ²Ğ½Ğ¾Ğ¼ Ğ¼ĞµĞ½Ñ. ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°, Ğ²Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğµ ĞºĞ½Ğ¾Ğ¿ĞºĞ¾Ğ¹ Ğ½Ğ¸Ğ¶Ğµ.")
    elif state == STATE_GENERATE:
        await message.answer("â—ï¸ĞĞ¶Ğ¸Ğ´Ğ°ĞµÑ‚ÑÑ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ğ°Ñ Ğ¸Ğ´ĞµÑ Ğ»Ğ¾Ğ³Ğ¾Ñ‚Ğ¸Ğ¿Ğ°.")
    elif state == STATE_VECTORIZE:
        await message.answer("â—ï¸ĞĞ¶Ğ¸Ğ´Ğ°ĞµÑ‚ÑÑ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ (Ñ„Ğ¾Ñ‚Ğ¾) Ğ´Ğ»Ñ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸.")
    else:
        await message.answer("â“ ĞĞµĞ¿Ğ¾Ğ½ÑÑ‚Ğ½Ğ¾Ğµ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ. ĞĞ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ 'â¬…ï¸ Ğ’ Ğ¼ĞµĞ½Ñ'.")

if __name__ == "__main__":
    asyncio.run(dp.start_polling(bot))


ğŸ”¹ config.py:
------------------------------------------------------------
import os
from dotenv import load_dotenv

# Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ¸Ğ· .env
load_dotenv()

TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")

# ĞŸÑ€Ğ¸Ğ²Ğ¾Ğ´Ğ¸Ğ¼ Ğº Ğ±ÑƒĞ»ĞµĞ²Ğ¾Ğ¼Ñƒ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ (true â†’ True, Ğ²ÑĞµ Ğ¾ÑÑ‚Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ â†’ False)
USE_PLACEHOLDER = os.getenv("USE_PLACEHOLDER", "false").strip().lower() == "true"

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")


ğŸ”¹ keyboards.py:
------------------------------------------------------------
from aiogram.types import ReplyKeyboardMarkup, KeyboardButton

def get_main_keyboard():
    return ReplyKeyboardMarkup(
        keyboard=[
            [KeyboardButton(text="ğŸ¨ Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ»Ğ¾Ğ³Ğ¾Ñ‚Ğ¸Ğ¿Ğ°")],
            [KeyboardButton(text="ğŸ–¼ Ğ’ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ")],
            [KeyboardButton(text="â„¹ï¸ Ğ˜Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ")],
        ],
        resize_keyboard=True
    )

def get_back_keyboard():
    return ReplyKeyboardMarkup(
        keyboard=[
            [KeyboardButton(text="â¬…ï¸ Ğ’ Ğ¼ĞµĞ½Ñ")],
        ],
        resize_keyboard=True
    )


ğŸ”¹ test.py:
------------------------------------------------------------
import requests
import os
from dotenv import load_dotenv

# Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ Ğ¸Ğ· .env Ñ„Ğ°Ğ¹Ğ»Ğ°
load_dotenv()

# ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ»Ğ¾Ğ³Ğ¸Ğ½ Ğ¸ Ğ¿Ğ°Ñ€Ğ¾Ğ»ÑŒ Ğ¸Ğ· .env
user = os.getenv('VECTORIZE_USER')
password = os.getenv('VECTORIZE_PASS')

# ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ
response = requests.post(
    'https://ru.vectorizer.ai/api/v1/vectorize',
    files={'image': open('image.jpg', 'rb')},
    data={'mode': 'test'},
    auth=(user, password)
)

# ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°
if response.status_code == requests.codes.ok:
    with open('result.svg', 'wb') as out:
        out.write(response.content)
else:
    print("Error:", response.status_code, response.text)

ğŸ”¹ tree.py:
------------------------------------------------------------
import os

IGNORE_DIRS = {"__pycache__", ".git", "venv", ".venv", "env", ".idea", ".mypy_cache", ".vscode"}
IGNORE_FILES = {".env"}

def list_files(base_path="."):
    summary = []

    for root, dirs, files in os.walk(base_path):
        # Ğ˜Ğ³Ğ½Ğ¾Ñ€Ğ¸Ñ€ÑƒĞµĞ¼ Ğ½ĞµĞ½ÑƒĞ¶Ğ½Ñ‹Ğµ Ğ¿Ğ°Ğ¿ĞºĞ¸
        dirs[:] = [d for d in dirs if d not in IGNORE_DIRS]
        files = [f for f in files if f.endswith(".py") and f not in IGNORE_FILES]

        # Ğ¡Ñ‚Ñ€Ğ¾Ğ¸Ğ¼ "Ğ¾Ñ‚Ğ½Ğ¾ÑĞ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿ÑƒÑ‚ÑŒ"
        rel_root = os.path.relpath(root, base_path)
        for f in files:
            path = os.path.join(rel_root, f) if rel_root != "." else f
            summary.append(path)

    return summary

def print_project_structure(base_path="."):
    print("ğŸ“ Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°:\n")
    for path in list_files(base_path):
        print(f" - {path}")
    print("\nğŸ“„ Ğ¡Ğ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ğ¼Ğ¾Ğµ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²:\n")

    for path in list_files(base_path):
        print(f"\nğŸ”¹ {path}:\n{'-'*60}")
        with open(os.path.join(base_path, path), "r", encoding="utf-8") as f:
            print(f.read())

if __name__ == "__main__":
    import sys
    with open('tree.txt', "w", encoding="utf-8") as f:
        sys.stdout = f  # Ğ¿ĞµÑ€ĞµĞ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ print Ğ² Ñ„Ğ°Ğ¹Ğ»
        print_project_structure()


ğŸ”¹ handlers\generation.py:
------------------------------------------------------------
from aiogram import types
from aiogram.fsm.context import FSMContext
from utils.states import GenerationStates
from utils.user_state import single_user_lock, is_generating, set_generating
from services.logo_generator import generate_image
from aiogram.types import BufferedInputFile
import logging

async def handle_idea(message: types.Message, state: FSMContext):
    state_now = await state.get_state()

    if state_now != GenerationStates.waiting_for_idea:
        return  # Ğ˜Ğ³Ğ½Ğ¾Ñ€Ğ¸Ñ€ÑƒĞµĞ¼, ĞµÑĞ»Ğ¸ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ Ğ½Ğµ Ğ² Ğ½ÑƒĞ¶Ğ½Ğ¾Ğ¼ Ñ€ĞµĞ¶Ğ¸Ğ¼Ğµ

    user_id = message.from_user.id

    if not message.text:
        await message.answer("â—ï¸ĞĞ¶Ğ¸Ğ´Ğ°ĞµÑ‚ÑÑ Ñ‚ĞµĞºÑÑ‚ Ñ Ğ¸Ğ´ĞµĞµĞ¹ Ğ»Ğ¾Ğ³Ğ¾Ñ‚Ğ¸Ğ¿Ğ°. ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°, Ğ½Ğ°Ğ¿Ğ¸ÑˆĞ¸Ñ‚Ğµ ÑĞ»Ğ¾Ğ²Ğ°Ğ¼Ğ¸.")
        return

    if is_generating(user_id):
        await message.answer("â³ ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°, Ğ´Ğ¾Ğ¶Ğ´Ğ¸Ñ‚ĞµÑÑŒ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ»Ğ¾Ğ³Ğ¾Ñ‚Ğ¸Ğ¿Ğ°.")
        return

    async with single_user_lock(user_id):
        set_generating(user_id, True)
        await message.answer("Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒÑ Ğ»Ğ¾Ğ³Ğ¾Ñ‚Ğ¸Ğ¿, Ğ¿Ğ¾Ğ´Ğ¾Ğ¶Ğ´Ğ¸ Ğ½ĞµĞ¼Ğ½Ğ¾Ğ³Ğ¾...")
        try:
            image = await generate_image(message.text)
            image.seek(0)
            input_file = BufferedInputFile(file=image.read(), filename="logo.png")
            await message.answer_photo(photo=input_file, caption="Ğ’Ğ¾Ñ‚ Ğ»Ğ¾Ğ³Ğ¾Ñ‚Ğ¸Ğ¿ Ğ¿Ğ¾ Ñ‚Ğ²Ğ¾ĞµĞ¹ Ğ¸Ğ´ĞµĞµ!")
            await message.answer("ğŸ’¡ ĞŸÑ€Ğ¸ÑˆĞ»Ğ¸ ĞµÑ‰Ñ‘ Ğ¸Ğ´ĞµÑ Ğ¸Ğ»Ğ¸ Ğ½Ğ°Ğ¶Ğ¼Ğ¸ 'â¬…ï¸ Ğ’ Ğ¼ĞµĞ½Ñ'.")
        except Exception as e:
            logging.exception("ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸")
            await message.answer(f"ĞŸÑ€Ğ¾Ğ¸Ğ·Ğ¾ÑˆĞ»Ğ° Ğ¾ÑˆĞ¸Ğ±ĞºĞ°: {e}")
        finally:
            set_generating(user_id, False)


ğŸ”¹ handlers\info.py:
------------------------------------------------------------
from aiogram import types
from keyboards import get_main_keyboard
from utils.user_state import set_user_state, STATE_MENU

async def info(message: types.Message):
    user_id = message.from_user.id
    set_user_state(user_id, STATE_MENU)
    await message.answer(
        "â„¹ï¸ Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ»Ğ¾Ğ³Ğ¾Ñ‚Ğ¸Ğ¿Ğ¾Ğ² Ñ‡ĞµÑ€ĞµĞ· GPT-4o + DALLÂ·E 3.\n\n"
        "Ğ–Ğ¼Ğ¸ 'ğŸ¨ Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ»Ğ¾Ğ³Ğ¾Ñ‚Ğ¸Ğ¿Ğ°' Ğ¸ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ÑŒ Ğ¸Ğ´ĞµÑ.\n"
        "Ğ˜Ğ»Ğ¸ Ğ²Ñ‹Ğ±ĞµÑ€Ğ¸ Ğ´Ñ€ÑƒĞ³Ğ¾Ğ¹ Ñ€ĞµĞ¶Ğ¸Ğ¼ Ğ½Ğ¸Ğ¶Ğµ ğŸ‘‡",
        reply_markup=get_main_keyboard()
    )

ğŸ”¹ handlers\prompt.py:
------------------------------------------------------------
from aiogram import types
from aiogram.fsm.context import FSMContext
from keyboards import get_back_keyboard
from utils.user_state import set_user_state, STATE_GENERATE
from utils.states import GenerationStates  # â† ĞĞµ Ğ·Ğ°Ğ±ÑƒĞ´ÑŒ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚

async def prompt_for_idea(message: types.Message, state: FSMContext):
    user_id = message.from_user.id
    set_user_state(user_id, STATE_GENERATE)
    await state.set_state(GenerationStates.waiting_for_idea)  # â† Ğ’ĞĞ–ĞĞ: ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ğ¼ FSM-ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ
    await message.answer(
        "âœï¸ ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ÑŒ Ğ¸Ğ´ĞµÑ Ğ»Ğ¾Ğ³Ğ¾Ñ‚Ğ¸Ğ¿Ğ° (Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€: 'Ğ»Ğ¾Ğ³Ğ¾Ñ‚Ğ¸Ğ¿ Ğ´Ğ»Ñ ĞºĞ¾Ñ„ĞµĞ¹Ğ½Ğ¸ Ğ² Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»Ğ¸ÑÑ‚Ğ¸Ñ‡Ğ½Ğ¾Ğ¼ ÑÑ‚Ğ¸Ğ»Ğµ')",
        reply_markup=get_back_keyboard()
    )


ğŸ”¹ handlers\start.py:
------------------------------------------------------------
from aiogram import types
from keyboards import get_main_keyboard
from utils.user_state import set_user_state, STATE_MENU

async def start(message: types.Message):
    user_id = message.from_user.id
    set_user_state(user_id, STATE_MENU)
    await message.answer(
        "ğŸ‘‹ ĞŸÑ€Ğ¸Ğ²ĞµÑ‚! Ğ¯ Ğ¿Ğ¾Ğ¼Ğ¾Ğ³Ñƒ ÑĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ»Ğ¾Ğ³Ğ¾Ñ‚Ğ¸Ğ¿. Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğµ:",
        reply_markup=get_main_keyboard()
    )

ğŸ”¹ handlers\vectorize.py:
------------------------------------------------------------
from aiogram import types
from aiogram.types import BufferedInputFile
from keyboards import get_back_keyboard
from utils.user_state import single_user_lock, is_generating, set_generating, set_user_state, STATE_VECTORIZE
import logging
import os
import requests
from dotenv import load_dotenv

load_dotenv()

VECTORIZE_USER = os.getenv("VECTORIZE_USER")
VECTORIZE_PASS = os.getenv("VECTORIZE_PASS")

async def ask_for_image(message: types.Message):
    user_id = message.from_user.id
    set_user_state(user_id, STATE_VECTORIZE)
    await message.answer(
        "ğŸ“¤ ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°, Ğ¿Ñ€Ğ¸ÑˆĞ»Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ (JPG, PNG Ğ¸ Ñ‚.Ğ´.).",
        reply_markup=get_back_keyboard()
    )

async def handle_vectorization_image(message: types.Message):
    user_id = message.from_user.id

    if is_generating(user_id):
        await message.answer("â³ ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°, Ğ´Ğ¾Ğ¶Ğ´Ğ¸Ñ‚ĞµÑÑŒ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ñ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸.")
        return

    async with single_user_lock(user_id):
        set_generating(user_id, True)
        try:
            photo = message.photo[-1]
            file = await message.bot.get_file(photo.file_id)
            downloaded_file = await message.bot.download_file(file.file_path)

            temp_path = f"temp_{user_id}.jpg"
            with open(temp_path, "wb") as f:
                f.write(downloaded_file.read())

            await message.answer("ğŸ”„ Ğ’ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ·ÑƒÑ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ, Ğ¿Ğ¾Ğ´Ğ¾Ğ¶Ğ´Ğ¸Ñ‚Ğµ...")

            with open(temp_path, "rb") as img:
                response = requests.post(
                    'https://ru.vectorizer.ai/api/v1/vectorize',
                    files={'image': img},
                    data={'mode': 'test'},
                    auth=(VECTORIZE_USER, VECTORIZE_PASS)
                )

            os.remove(temp_path)

            if response.status_code == 200:
                svg_path = f"vectorized_{user_id}.svg"
                with open(svg_path, "wb") as f:
                    f.write(response.content)

                with open(svg_path, "rb") as f:
                    svg_file = BufferedInputFile(file=f.read(), filename="vectorized.svg")
                    await message.answer_document(document=svg_file, caption="âœ… Ğ’ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ°!")
                os.remove(svg_path)
            else:
                await message.answer(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸: {response.status_code}\n{response.text}")

        except Exception as e:
            logging.exception("ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸")
            await message.answer(f"âš ï¸ ĞŸÑ€Ğ¾Ğ¸Ğ·Ğ¾ÑˆĞ»Ğ° Ğ¾ÑˆĞ¸Ğ±ĞºĞ°: {e}")
        finally:
            set_generating(user_id, False)


ğŸ”¹ handlers\__init__.py:
------------------------------------------------------------


ğŸ”¹ services\logo_generator.py:
------------------------------------------------------------
import requests
from io import BytesIO
import asyncio
from config import USE_PLACEHOLDER, OPENAI_API_KEY

async def generate_image(prompt: str) -> BytesIO:
    if USE_PLACEHOLDER:
        await asyncio.sleep(2)
        url = "https://picsum.photos/1024"
        response = requests.get(url)
        response.raise_for_status()
        return BytesIO(response.content)

    from openai import OpenAI
    client = OpenAI(api_key=OPENAI_API_KEY)

    chat = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "Ğ¢Ñ‹ ÑĞ¾Ğ·Ğ´Ğ°ĞµÑˆÑŒ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚ Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ»Ğ¾Ğ³Ğ¾Ñ‚Ğ¸Ğ¿Ğ° Ñ‡ĞµÑ€ĞµĞ· DALLÂ·E 3."},
            {"role": "user", "content": prompt}
        ]
    )

    prompt_dalle = chat.choices[0].message.content.strip()

    image_response = client.images.generate(
        model="dall-e-3",
        prompt=prompt_dalle,
        n=1,
        size="1024x1024",
        quality="standard",
        style="vivid",
    )

    image_url = image_response.data[0].url
    img_data = requests.get(image_url)
    img_data.raise_for_status()

    return BytesIO(img_data.content)


ğŸ”¹ services\__init__.py:
------------------------------------------------------------


ğŸ”¹ utils\states.py:
------------------------------------------------------------
from aiogram.fsm.state import StatesGroup, State

class GenerationStates(StatesGroup):
    waiting_for_idea = State()


ğŸ”¹ utils\user_state.py:
------------------------------------------------------------
import asyncio
from contextlib import asynccontextmanager

user_locks = {}
user_generation_flags = {}
user_states = {}

STATE_MENU = "menu"
STATE_GENERATE = "generate"
STATE_VECTORIZE = "vectorize"

@asynccontextmanager
async def single_user_lock(user_id: int):
    lock = user_locks.setdefault(user_id, asyncio.Lock())
    async with lock:
        yield

def is_generating(user_id):
    return user_generation_flags.get(user_id, False)

def set_generating(user_id, value: bool):
    user_generation_flags[user_id] = value

def set_user_state(user_id: int, state: str):
    user_states[user_id] = state

def get_user_state(user_id: int) -> str:
    return user_states.get(user_id, STATE_MENU)


ğŸ”¹ utils\__init__.py:
------------------------------------------------------------

